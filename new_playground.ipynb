{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgi import test\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import halfnorm, expon, uniform, chi, norm\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.layers import Dense, Input, Conv2D, MaxPool2D, LSTM, add\n",
    "from keras.layers import Activation, Dropout, Flatten, Embedding\n",
    "from keras.models import Model, Sequential\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import scipy.stats\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential distribution generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exponential(amount): #Generates a popular playlist\n",
    "    data = {}\n",
    "    for i in range(amount):\n",
    "        data[i] = expon.pdf(i, scale=(amount/7)) \n",
    "    return data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_exponential_inv(amount): #Generates a \"niche\" (unpopuar) playlist \n",
    "    data = {}\n",
    "    for i in range(amount):\n",
    "        data[amount - 1 - i] = expon.pdf(i, scale=(amount/7)) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform distribution generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_uniform(amount): #Generates an uniform distribution among the items\n",
    "    data = {}\n",
    "    for i in range(amount):\n",
    "        data[i] = uniform.pdf(i, scale=amount) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_cumulative_prob() GETS THE CUMULATIVE PROBABIITIES OF ITEMS (for later selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_prob(y): \n",
    "\n",
    "    cum_prob = {}\n",
    "    cum_prob[0] = y[0]\n",
    "\n",
    "    for i in range(1, 300):\n",
    "        cum_prob[i] = cum_prob[i-1] + y[i]\n",
    "    return cum_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_playlist() generates a playlist based on the cumulative probabilities its given (for popualar, normal, and rare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playlists(cum_prob): #CREATES A RANDOM PLAYLLIST\n",
    "\n",
    "    playlist = [] #empty toy playlist\n",
    "\n",
    "    #create random playlist (like this bc they dont add to 1)\n",
    "    while len(playlist) < 20:\n",
    "\n",
    "        prob = np.random.random()\n",
    "        #print(prob)\n",
    "        finished = False\n",
    "        i = 0\n",
    "        while i < 300 and finished == False:\n",
    "            if prob < cum_prob[i] and i not in playlist:\n",
    "                playlist.append(i)\n",
    "                finished = True\n",
    "            i += 1\n",
    "\n",
    "    playlist.sort()\n",
    "    return playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_songs_ordered(songs): #RETURNS A LIST OF SONGS ORDERED BY POPULARITY (AMONG ALL THE PLAYLISTS)\n",
    "    ordered_songs = []\n",
    "    songs_copy = copy.deepcopy(songs)\n",
    "\n",
    "    while songs_copy: \n",
    "        max_value = max(songs_copy, key=songs_copy.get)\n",
    "        ordered_songs.append(max_value)\n",
    "        songs_copy.pop(max_value)\n",
    "    #print(\"Highest used song: \", max_value, \" with \", songs_copy[max_value], \" instances\")\n",
    "    return ordered_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(list): \n",
    "    elems = []\n",
    "    pred = []\n",
    "    size = len(list)\n",
    "    for i in range(size - 1):\n",
    "        elems.append(list[i])\n",
    "        pred.append(list[i + 1])\n",
    "    d = {'Song':elems, 'Next':pred}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_dataframe(probs):\n",
    "    songs = []\n",
    "    next = []\n",
    "    for i in range(len(probs)):\n",
    "        songs.append(i)\n",
    "        next.append(probs[i])\n",
    "    for i in range(len(next[299])):\n",
    "        next[299][i] = 0\n",
    "    next[299][298] = 1\n",
    "    dataframe_next = pd.DataFrame(next)\n",
    "    d = {'Song': songs}\n",
    "    df = pd.DataFrame(d)\n",
    "    result = pd.concat([df, dataframe_next], axis=1, join='inner')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we stop using probabilities use this function not create_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(pairs):\n",
    "    songs = []\n",
    "    next = []\n",
    "    for i in range(len(pairs)):\n",
    "        #max_num = 0\n",
    "        songs.append(i)\n",
    "        #max_num = max(pairs[i])\n",
    "        pred_song = np.argmax(pairs[i])\n",
    "        next.append(pred_song)\n",
    "    d = {\"Song\":songs, \"Next\":next}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dataframe):\n",
    "    X = dataframe['Song']\n",
    "    y = dataframe['Next']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    train = {'Song':X_train, 'Next': y_train}\n",
    "    test = {'Song':X_test, 'Next': y_test}\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset_prob(dataframe):\n",
    "    X = dataframe['Song']\n",
    "    dataframe = dataframe.drop('Song', axis=1)\n",
    "    y = dataframe\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train = X\n",
    "    y_train = y\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_data(data, mean, std):\n",
    "    songs_norm = (data['Song'] - mean) / std\n",
    "    data['Song'] = songs_norm\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case we need tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_dataset(train, test):\n",
    "    train_X = tf.data.Dataset.from_tensor_slices(train['Song'])\n",
    "    train_Y = tf.data.Dataset.from_tensor_slices(train['Next'])\n",
    "\n",
    "    train_dataset = tf.data.Dataset.zip((train_X, train_Y))\n",
    "    train_dataset = train_dataset.shuffle(1000).batch(64)\n",
    "    train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    test_X = tf.data.Dataset.from_tensor_slices(test['Song'])\n",
    "    test_Y = tf.data.Dataset.from_tensor_slices(test['Next'])\n",
    "\n",
    "    test_dataset = tf.data.Dataset.zip((test_X, test_Y))\n",
    "    test_dataset = test_dataset.shuffle(1000).batch(64)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create_pairs() creates pairs of numbers, indicating the number of times one appears after the other in the playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(playlists): #playlists should be a list of lists, ordered\n",
    "    pairs = np.zeros((300,300))\n",
    "    for playlist in playlists:\n",
    "        for i in range(len(playlist)-1):\n",
    "            pairs[playlist[i]][playlist[i+1]] += 1\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_playists(playlists):\n",
    "    for playlist in playlists:\n",
    "        playlist.sort()\n",
    "    return playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities(pairs): #Gets the probabilities associated to each pair of numbers, which song is more likely\n",
    "    for num in range(len(pairs)): #to go after the other\n",
    "        total = sum(pairs[num])\n",
    "        pairs[num] /= total\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nll(true_song, probs): #true_song has to be in [0,0,0...1,0] format, being the 1 in the correct song index\n",
    "    nll = 0                     #probs is the output of the nn\n",
    "    for i in range(len(true_song)):\n",
    "        nll += true_song[i] * probs[i]\n",
    "    nll = -np.log(nll)\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nll_list(expected, idx, predictions): #Returns a list of uncertainties for each prediction\n",
    "    nll_list = []\n",
    "    j = 0\n",
    "    for i in idx:\n",
    "        true_song = get_true_song(expected[i])\n",
    "        nll_list.append(get_nll(true_song, predictions[j]))\n",
    "        j += 1\n",
    "    return nll_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_song(next_songs): #returns expected song, represented as one_hot\n",
    "    true_song = []\n",
    "    item = np.argmax(next_songs)\n",
    "    for i in range(len(next_songs)):\n",
    "        if i == item:\n",
    "            true_song.append(1)\n",
    "            #print(\"Predicted song: \", item)\n",
    "        else:\n",
    "            true_song.append(0)\n",
    "    return true_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_predictions(pred): #Transforms the predictions into a one_hot of the most likely song\n",
    "    max_index = np.argmax(pred)\n",
    "    new_pred = np.zeros(len(pred))\n",
    "    new_pred[max_index] = 1\n",
    "    return new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred, truth):\n",
    "    count = 0\n",
    "    size = len(pred)\n",
    "    for i in range(size):\n",
    "        cont = True\n",
    "        j = 0\n",
    "        while cont and j < size:\n",
    "            if pred[i][j] != truth[i][j]:\n",
    "                cont = False\n",
    "            j += 1\n",
    "        if cont:\n",
    "            count += 1\n",
    "    return count / size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    input = Input(shape=(1,))\n",
    "    model.add(input)\n",
    "    model.add(Dense(10, activation='tanh'))\n",
    "    model.add(Dense(20, activation='tanh'))\n",
    "    model.add(Dense(30, activation='tanh'))\n",
    "    model.add(Dense(40, activation='tanh'))\n",
    "    model.add(Dense(50, activation='tanh'))\n",
    "    model.add(Dense(60, activation='tanh'))\n",
    "    model.add(Dense(40, activation='tanh'))\n",
    "    model.add(Dense(70, activation='tanh'))\n",
    "    model.add(Dense(300, activation='sigmoid')) #model.add(Dense(1))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_playists_popularity(playists): #FUNCTION THAT PLOTS AL THE SONGS APPEARANCES OF ALL PLAYLISTS\n",
    "    #playlists is a list of lists\n",
    "\n",
    "    num_appearances = {} #Dictionary to store the number of times a song is in a playlist\n",
    "\n",
    "    for playlist in playists:\n",
    "        for song in playlist:\n",
    "            if song in num_appearances.keys():\n",
    "                num_appearances[song] += 1\n",
    "            else:\n",
    "                num_appearances[song] = 1\n",
    "\n",
    "    id, counts = zip(*num_appearances.items())\n",
    "    plt.scatter(id, counts)\n",
    "    plt.xlabel(\"Song number\")\n",
    "    plt.ylabel(\"Number of appearances\")\n",
    "    plt.show() #BREAK POINT HERE TO SEE THE PLOT\n",
    "    return num_appearances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_uncertainty_pop(popuarity, uncertainty):\n",
    "    id, counts = zip(*popuarity.items())\n",
    "    plot_dict = {}\n",
    "    i = 0\n",
    "    for num in counts:\n",
    "        #what if its already a number\n",
    "        plot_dict[num] = uncertainty[i]\n",
    "        i += 1\n",
    "    pop, unc = zip(*plot_dict.items())\n",
    "    print(scipy.stats.pearsonr(pop, unc))\n",
    "    print(scipy.stats.spearmanr(pop, unc))\n",
    "    print(scipy.stats.kendalltau(pop, unc))\n",
    "    plt.scatter(pop, unc)\n",
    "    plt.xlabel(\"Popuarity\")\n",
    "    plt.ylabel(\"Uncertainty\")\n",
    "    plt.show() #BREAK POINT HERE TO SEE THE PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here it begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = generate_exponential(300)\n",
    "#data = generate_exponential_inv(300)\n",
    "#data = generate_uniform(300)\n",
    "lists = sorted(data.items())\n",
    "x, y = zip(*lists)\n",
    "cum_prob = get_cumulative_prob(y)\n",
    "playlist = get_playlists(cum_prob)\n",
    "plt.plot(x, y)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "playlist_list = []\n",
    "data_exp = generate_exponential(300)\n",
    "data_exp_inv = generate_exponential_inv(300)\n",
    "data_uniform = generate_uniform(300)\n",
    "\n",
    "data_exp = sorted(data_exp.items())\n",
    "_, y_exp = zip(*data_exp)\n",
    "\n",
    "data_exp_inv = sorted(data_exp_inv.items())\n",
    "_, y_exp_inv = zip(*data_exp_inv)\n",
    "\n",
    "data_uniform = sorted(data_uniform.items())\n",
    "_, y_uni = zip(*data_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = random.choices(population=[0,1,2], weights=[0.2307,0.6923,0.077], k=3000) #returns a list of choices\n",
    "\n",
    "cum_prob_exp = get_cumulative_prob(y_exp) #GETS DIFFERENT PROBABIITIES\n",
    "cum_prob_inv = get_cumulative_prob(y_exp_inv)\n",
    "cum_prob_uni = get_cumulative_prob(y_uni)\n",
    "\n",
    "for i in type: #GET A RANDOM PLAYLIST OF A SPECIFIC TYPE\n",
    "    if i == 1:\n",
    "        pl = get_playlists(cum_prob_exp)\n",
    "    elif i == 2:\n",
    "        pl = get_playlists(cum_prob_inv)\n",
    "    else:\n",
    "        pl = get_playlists(cum_prob_uni)\n",
    "    playlist_list.append(pl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_18756\\4282934075.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pairs[num] /= total\n"
     ]
    }
   ],
   "source": [
    "popuarity = plot_playists_popularity(playlist_list) #returns the number of appearances of each song\n",
    "playlists_ordered = order_playists(playlist_list)\n",
    "pairs = create_pairs(playlist_list) #playlists_ordered\n",
    "pairs2 = get_probabilities(pairs)\n",
    "df2 = get_prob_dataframe(pairs2)\n",
    "#df = create_training_data(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data, test_data= split_dataset(df)\n",
    "X_train, X_test, y_train, y_test = split_dataset_prob(df2)\n",
    "#train_dataset, test_dataset = get_tf_dataset(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "300/300 [==============================] - 1s 1ms/step - loss: 5.5874 - accuracy: 0.0067 - val_loss: 5.2727 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 5.2866 - accuracy: 0.0000e+00 - val_loss: 5.2790 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 5.0882 - accuracy: 0.0033 - val_loss: 5.0224 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 5.1346 - accuracy: 0.0067 - val_loss: 4.7684 - val_accuracy: 0.0167\n",
      "Epoch 5/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 5.0162 - accuracy: 0.0067 - val_loss: 4.9438 - val_accuracy: 0.0333\n",
      "Epoch 6/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.8541 - accuracy: 0.0100 - val_loss: 4.7884 - val_accuracy: 0.0167\n",
      "Epoch 7/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.7631 - accuracy: 0.0067 - val_loss: 4.6167 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.7056 - accuracy: 0.0033 - val_loss: 4.4243 - val_accuracy: 0.0167\n",
      "Epoch 9/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.7106 - accuracy: 0.0133 - val_loss: 4.6792 - val_accuracy: 0.0333\n",
      "Epoch 10/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.5330 - accuracy: 0.0133 - val_loss: 4.3454 - val_accuracy: 0.1167\n",
      "Epoch 11/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.5835 - accuracy: 0.0067 - val_loss: 4.4059 - val_accuracy: 0.0333\n",
      "Epoch 12/200\n",
      "300/300 [==============================] - 0s 827us/step - loss: 4.7632 - accuracy: 0.0067 - val_loss: 5.1376 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "300/300 [==============================] - 0s 810us/step - loss: 5.0489 - accuracy: 0.0033 - val_loss: 4.3559 - val_accuracy: 0.0500\n",
      "Epoch 14/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 4.4893 - accuracy: 0.0067 - val_loss: 4.3683 - val_accuracy: 0.0500\n",
      "Epoch 15/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.5931 - accuracy: 0.0100 - val_loss: 5.2711 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "300/300 [==============================] - 0s 837us/step - loss: 4.5875 - accuracy: 0.0067 - val_loss: 4.2697 - val_accuracy: 0.0333\n",
      "Epoch 17/200\n",
      "300/300 [==============================] - 0s 834us/step - loss: 4.3509 - accuracy: 0.0133 - val_loss: 4.4874 - val_accuracy: 0.0167\n",
      "Epoch 18/200\n",
      "300/300 [==============================] - 0s 830us/step - loss: 4.3875 - accuracy: 0.0100 - val_loss: 4.4253 - val_accuracy: 0.0333\n",
      "Epoch 19/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 4.5704 - accuracy: 0.0100 - val_loss: 4.3679 - val_accuracy: 0.0500\n",
      "Epoch 20/200\n",
      "300/300 [==============================] - 0s 803us/step - loss: 4.5784 - accuracy: 0.0000e+00 - val_loss: 4.2124 - val_accuracy: 0.0333\n",
      "Epoch 21/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 4.3027 - accuracy: 0.0167 - val_loss: 4.4557 - val_accuracy: 0.0167\n",
      "Epoch 22/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 4.5648 - accuracy: 0.0033 - val_loss: 4.4531 - val_accuracy: 0.0167\n",
      "Epoch 23/200\n",
      "300/300 [==============================] - 0s 840us/step - loss: 4.5323 - accuracy: 0.0133 - val_loss: 4.1247 - val_accuracy: 0.0167\n",
      "Epoch 24/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.3897 - accuracy: 0.0233 - val_loss: 4.0992 - val_accuracy: 0.0333\n",
      "Epoch 25/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.5888 - accuracy: 0.0033 - val_loss: 5.7018 - val_accuracy: 0.0167\n",
      "Epoch 26/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 4.5126 - accuracy: 0.0133 - val_loss: 4.1013 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.2480 - accuracy: 0.0100 - val_loss: 4.3545 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 4.2978 - accuracy: 0.0067 - val_loss: 4.0623 - val_accuracy: 0.0333\n",
      "Epoch 29/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.3350 - accuracy: 0.0033 - val_loss: 4.0463 - val_accuracy: 0.0833\n",
      "Epoch 30/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.4313 - accuracy: 0.0200 - val_loss: 4.2705 - val_accuracy: 0.0333\n",
      "Epoch 31/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.3677 - accuracy: 0.0067 - val_loss: 4.7849 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.3665 - accuracy: 0.0133 - val_loss: 4.0580 - val_accuracy: 0.0167\n",
      "Epoch 33/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.3764 - accuracy: 0.0167 - val_loss: 4.0119 - val_accuracy: 0.0167\n",
      "Epoch 34/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.2643 - accuracy: 0.0033 - val_loss: 4.4977 - val_accuracy: 0.0333\n",
      "Epoch 35/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.3607 - accuracy: 0.0067 - val_loss: 4.6157 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.5854 - accuracy: 0.0167 - val_loss: 4.3510 - val_accuracy: 0.0333\n",
      "Epoch 37/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.3459 - accuracy: 0.0133 - val_loss: 4.2864 - val_accuracy: 0.0333\n",
      "Epoch 38/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.5502 - accuracy: 0.0133 - val_loss: 4.7350 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.4038 - accuracy: 0.0133 - val_loss: 4.0399 - val_accuracy: 0.0333\n",
      "Epoch 40/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.3447 - accuracy: 0.0133 - val_loss: 4.5009 - val_accuracy: 0.0333\n",
      "Epoch 41/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 4.5685 - accuracy: 0.0167 - val_loss: 4.3975 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.3442 - accuracy: 0.0067 - val_loss: 4.7873 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.3915 - accuracy: 0.0067 - val_loss: 4.0769 - val_accuracy: 0.0333\n",
      "Epoch 44/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 4.3668 - accuracy: 0.0133 - val_loss: 4.2295 - val_accuracy: 0.0167\n",
      "Epoch 45/200\n",
      "300/300 [==============================] - 0s 820us/step - loss: 4.4363 - accuracy: 0.0100 - val_loss: 4.1559 - val_accuracy: 0.0667\n",
      "Epoch 46/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 4.4785 - accuracy: 0.0033 - val_loss: 4.2646 - val_accuracy: 0.0333\n",
      "Epoch 47/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.4852 - accuracy: 0.0100 - val_loss: 4.0881 - val_accuracy: 0.0500\n",
      "Epoch 48/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.1796 - accuracy: 0.0233 - val_loss: 4.0118 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 4.1100 - accuracy: 0.0133 - val_loss: 4.2392 - val_accuracy: 0.0833\n",
      "Epoch 50/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.7599 - accuracy: 0.0067 - val_loss: 4.5708 - val_accuracy: 0.0167\n",
      "Epoch 51/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.4874 - accuracy: 0.0000e+00 - val_loss: 4.1376 - val_accuracy: 0.0667\n",
      "Epoch 52/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.4785 - accuracy: 0.0167 - val_loss: 4.2454 - val_accuracy: 0.0333\n",
      "Epoch 53/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.2426 - accuracy: 0.0100 - val_loss: 4.0052 - val_accuracy: 0.0500\n",
      "Epoch 54/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.3676 - accuracy: 0.0100 - val_loss: 4.1458 - val_accuracy: 0.0500\n",
      "Epoch 55/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.4299 - accuracy: 0.0133 - val_loss: 4.2945 - val_accuracy: 0.0667\n",
      "Epoch 56/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 4.2938 - accuracy: 0.0067 - val_loss: 4.0876 - val_accuracy: 0.0667\n",
      "Epoch 57/200\n",
      "300/300 [==============================] - 0s 830us/step - loss: 4.3074 - accuracy: 0.0100 - val_loss: 4.3286 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "300/300 [==============================] - 0s 837us/step - loss: 4.6866 - accuracy: 0.0167 - val_loss: 4.3362 - val_accuracy: 0.0167\n",
      "Epoch 59/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 4.2894 - accuracy: 0.0167 - val_loss: 4.0694 - val_accuracy: 0.0500\n",
      "Epoch 60/200\n",
      "300/300 [==============================] - 0s 804us/step - loss: 4.4112 - accuracy: 0.0133 - val_loss: 4.6490 - val_accuracy: 0.0167\n",
      "Epoch 61/200\n",
      "300/300 [==============================] - 0s 847us/step - loss: 4.2442 - accuracy: 0.0133 - val_loss: 4.0569 - val_accuracy: 0.0333\n",
      "Epoch 62/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 4.1946 - accuracy: 0.0200 - val_loss: 3.9996 - val_accuracy: 0.0167\n",
      "Epoch 63/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.2492 - accuracy: 0.0167 - val_loss: 4.3830 - val_accuracy: 0.0667\n",
      "Epoch 64/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 4.3589 - accuracy: 0.0100 - val_loss: 4.1956 - val_accuracy: 0.0333\n",
      "Epoch 65/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 4.1244 - accuracy: 0.0133 - val_loss: 4.2256 - val_accuracy: 0.0500\n",
      "Epoch 66/200\n",
      "300/300 [==============================] - 0s 803us/step - loss: 5.9605 - accuracy: 0.0100 - val_loss: 6.1938 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "300/300 [==============================] - 0s 800us/step - loss: 5.5530 - accuracy: 0.0000e+00 - val_loss: 5.3715 - val_accuracy: 0.0167\n",
      "Epoch 68/200\n",
      "300/300 [==============================] - 0s 803us/step - loss: 5.2971 - accuracy: 0.0033 - val_loss: 5.1897 - val_accuracy: 0.0333\n",
      "Epoch 69/200\n",
      "300/300 [==============================] - 0s 803us/step - loss: 5.2401 - accuracy: 0.0000e+00 - val_loss: 5.0931 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 5.1150 - accuracy: 0.0067 - val_loss: 4.9123 - val_accuracy: 0.0333\n",
      "Epoch 71/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.9704 - accuracy: 0.0067 - val_loss: 4.7303 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.7057 - accuracy: 0.0033 - val_loss: 4.5617 - val_accuracy: 0.0333\n",
      "Epoch 73/200\n",
      "300/300 [==============================] - 0s 810us/step - loss: 4.8667 - accuracy: 0.0000e+00 - val_loss: 5.0429 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 4.7820 - accuracy: 0.0067 - val_loss: 4.4958 - val_accuracy: 0.0333\n",
      "Epoch 75/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 4.5503 - accuracy: 0.0100 - val_loss: 4.5219 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "300/300 [==============================] - 0s 800us/step - loss: 4.7184 - accuracy: 0.0167 - val_loss: 4.3744 - val_accuracy: 0.0667\n",
      "Epoch 77/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.4567 - accuracy: 0.0100 - val_loss: 4.2735 - val_accuracy: 0.0333\n",
      "Epoch 78/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.3734 - accuracy: 0.0033 - val_loss: 4.8054 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.5629 - accuracy: 0.0067 - val_loss: 4.4348 - val_accuracy: 0.0333\n",
      "Epoch 80/200\n",
      "300/300 [==============================] - 0s 797us/step - loss: 4.6300 - accuracy: 0.0133 - val_loss: 4.3525 - val_accuracy: 0.0167\n",
      "Epoch 81/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 4.3123 - accuracy: 0.0100 - val_loss: 4.2051 - val_accuracy: 0.0167\n",
      "Epoch 82/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.5429 - accuracy: 0.0167 - val_loss: 4.5824 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "300/300 [==============================] - 0s 810us/step - loss: 4.3825 - accuracy: 0.0100 - val_loss: 4.8225 - val_accuracy: 0.0167\n",
      "Epoch 84/200\n",
      "300/300 [==============================] - 0s 803us/step - loss: 4.3741 - accuracy: 0.0133 - val_loss: 4.4952 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 4.3567 - accuracy: 0.0200 - val_loss: 4.5881 - val_accuracy: 0.0333\n",
      "Epoch 86/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 4.2488 - accuracy: 0.0033 - val_loss: 4.1558 - val_accuracy: 0.0833\n",
      "Epoch 87/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.4337 - accuracy: 0.0133 - val_loss: 4.1310 - val_accuracy: 0.0167\n",
      "Epoch 88/200\n",
      "300/300 [==============================] - 0s 820us/step - loss: 4.4107 - accuracy: 0.0033 - val_loss: 4.1736 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 4.3886 - accuracy: 0.0100 - val_loss: 4.1810 - val_accuracy: 0.0500\n",
      "Epoch 90/200\n",
      "300/300 [==============================] - 0s 827us/step - loss: 4.3470 - accuracy: 0.0167 - val_loss: 4.3055 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.2454 - accuracy: 0.0200 - val_loss: 4.7679 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.2974 - accuracy: 0.0067 - val_loss: 6.3043 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "300/300 [==============================] - 0s 813us/step - loss: 4.6104 - accuracy: 0.0033 - val_loss: 6.4444 - val_accuracy: 0.0167\n",
      "Epoch 94/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.6057 - accuracy: 0.0000e+00 - val_loss: 4.1624 - val_accuracy: 0.0500\n",
      "Epoch 95/200\n",
      "300/300 [==============================] - 0s 830us/step - loss: 4.2116 - accuracy: 0.0100 - val_loss: 4.6903 - val_accuracy: 0.0167\n",
      "Epoch 96/200\n",
      "300/300 [==============================] - 0s 817us/step - loss: 4.2472 - accuracy: 0.0100 - val_loss: 4.0898 - val_accuracy: 0.0167\n",
      "Epoch 97/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.5225 - accuracy: 0.0133 - val_loss: 4.4839 - val_accuracy: 0.0500\n",
      "Epoch 98/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.2304 - accuracy: 0.0100 - val_loss: 4.1366 - val_accuracy: 0.0500\n",
      "Epoch 99/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.3467 - accuracy: 0.0033 - val_loss: 4.0849 - val_accuracy: 0.0167\n",
      "Epoch 100/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.5573 - accuracy: 0.0100 - val_loss: 4.1116 - val_accuracy: 0.0167\n",
      "Epoch 101/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.3103 - accuracy: 0.0133 - val_loss: 4.1656 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "300/300 [==============================] - 0s 803us/step - loss: 4.2847 - accuracy: 0.0100 - val_loss: 4.2028 - val_accuracy: 0.0333\n",
      "Epoch 103/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.2377 - accuracy: 0.0067 - val_loss: 4.6167 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "300/300 [==============================] - 0s 810us/step - loss: 4.2524 - accuracy: 0.0167 - val_loss: 4.0590 - val_accuracy: 0.0167\n",
      "Epoch 105/200\n",
      "300/300 [==============================] - 0s 844us/step - loss: 4.1133 - accuracy: 0.0200 - val_loss: 3.9757 - val_accuracy: 0.0167\n",
      "Epoch 106/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.2411 - accuracy: 0.0100 - val_loss: 4.4823 - val_accuracy: 0.0167\n",
      "Epoch 107/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.3180 - accuracy: 0.0233 - val_loss: 4.1778 - val_accuracy: 0.0167\n",
      "Epoch 108/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.1529 - accuracy: 0.0100 - val_loss: 4.2983 - val_accuracy: 0.0333\n",
      "Epoch 109/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.1603 - accuracy: 0.0100 - val_loss: 4.0546 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "300/300 [==============================] - 0s 827us/step - loss: 4.1876 - accuracy: 0.0233 - val_loss: 4.1868 - val_accuracy: 0.0167\n",
      "Epoch 111/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.4051 - accuracy: 0.0067 - val_loss: 4.4521 - val_accuracy: 0.0333\n",
      "Epoch 112/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.3932 - accuracy: 0.0100 - val_loss: 4.2125 - val_accuracy: 0.0167\n",
      "Epoch 113/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.2958 - accuracy: 0.0167 - val_loss: 3.9939 - val_accuracy: 0.0500\n",
      "Epoch 114/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.0582 - accuracy: 0.0233 - val_loss: 4.2838 - val_accuracy: 0.0167\n",
      "Epoch 115/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.2933 - accuracy: 0.0067 - val_loss: 4.2345 - val_accuracy: 0.0167\n",
      "Epoch 116/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.1278 - accuracy: 0.0033 - val_loss: 4.0016 - val_accuracy: 0.0333\n",
      "Epoch 117/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.2374 - accuracy: 0.0100 - val_loss: 4.0411 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.2575 - accuracy: 0.0133 - val_loss: 4.0451 - val_accuracy: 0.0333\n",
      "Epoch 119/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.2448 - accuracy: 0.0200 - val_loss: 3.9795 - val_accuracy: 0.0333\n",
      "Epoch 120/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.7809 - accuracy: 0.0233 - val_loss: 4.8550 - val_accuracy: 0.0167\n",
      "Epoch 121/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.9261 - accuracy: 0.0000e+00 - val_loss: 4.7520 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.7565 - accuracy: 0.0000e+00 - val_loss: 4.2520 - val_accuracy: 0.0333\n",
      "Epoch 123/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.3182 - accuracy: 0.0100 - val_loss: 4.0579 - val_accuracy: 0.0333\n",
      "Epoch 124/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.1905 - accuracy: 0.0067 - val_loss: 4.3188 - val_accuracy: 0.0833\n",
      "Epoch 125/200\n",
      "300/300 [==============================] - 0s 800us/step - loss: 4.3589 - accuracy: 0.0100 - val_loss: 4.5972 - val_accuracy: 0.0333\n",
      "Epoch 126/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.2352 - accuracy: 0.0133 - val_loss: 3.9969 - val_accuracy: 0.0333\n",
      "Epoch 127/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.2162 - accuracy: 0.0367 - val_loss: 4.7395 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.1436 - accuracy: 0.0233 - val_loss: 3.9362 - val_accuracy: 0.0667\n",
      "Epoch 129/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.0892 - accuracy: 0.0033 - val_loss: 4.4905 - val_accuracy: 0.0333\n",
      "Epoch 130/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.2593 - accuracy: 0.0100 - val_loss: 4.1515 - val_accuracy: 0.0500\n",
      "Epoch 131/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.1735 - accuracy: 0.0133 - val_loss: 4.2551 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.1416 - accuracy: 0.0167 - val_loss: 4.4227 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.0977 - accuracy: 0.0300 - val_loss: 4.0138 - val_accuracy: 0.0167\n",
      "Epoch 134/200\n",
      "300/300 [==============================] - 0s 807us/step - loss: 4.3539 - accuracy: 0.0167 - val_loss: 4.0517 - val_accuracy: 0.0167\n",
      "Epoch 135/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.7169 - accuracy: 0.0100 - val_loss: 4.4678 - val_accuracy: 0.0333\n",
      "Epoch 136/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.4421 - accuracy: 0.0033 - val_loss: 4.3274 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.3354 - accuracy: 0.0133 - val_loss: 4.1344 - val_accuracy: 0.0500\n",
      "Epoch 138/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 4.4181 - accuracy: 0.0067 - val_loss: 4.1763 - val_accuracy: 0.0667\n",
      "Epoch 139/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.3424 - accuracy: 0.0133 - val_loss: 4.2509 - val_accuracy: 0.0167\n",
      "Epoch 140/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.4116 - accuracy: 0.0033 - val_loss: 4.1924 - val_accuracy: 0.0167\n",
      "Epoch 141/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.1885 - accuracy: 0.0167 - val_loss: 4.0706 - val_accuracy: 0.0333\n",
      "Epoch 142/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.3150 - accuracy: 0.0133 - val_loss: 5.4498 - val_accuracy: 0.0167\n",
      "Epoch 143/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.4652 - accuracy: 0.0167 - val_loss: 4.0566 - val_accuracy: 0.0167\n",
      "Epoch 144/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.2926 - accuracy: 0.0133 - val_loss: 4.1341 - val_accuracy: 0.0167\n",
      "Epoch 145/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.5637 - accuracy: 0.0100 - val_loss: 5.1553 - val_accuracy: 0.0333\n",
      "Epoch 146/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.3571 - accuracy: 0.0100 - val_loss: 4.1632 - val_accuracy: 0.0333\n",
      "Epoch 147/200\n",
      "300/300 [==============================] - 0s 757us/step - loss: 4.1069 - accuracy: 0.0167 - val_loss: 4.0225 - val_accuracy: 0.0500\n",
      "Epoch 148/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.1957 - accuracy: 0.0233 - val_loss: 4.2013 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.7285 - accuracy: 0.0067 - val_loss: 4.3690 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.1898 - accuracy: 0.0167 - val_loss: 4.0701 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.3695 - accuracy: 0.0100 - val_loss: 4.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 4.2550 - accuracy: 0.0133 - val_loss: 4.4669 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.2900 - accuracy: 0.0167 - val_loss: 4.1974 - val_accuracy: 0.0167\n",
      "Epoch 154/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.4936 - accuracy: 0.0100 - val_loss: 4.9366 - val_accuracy: 0.0333\n",
      "Epoch 155/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.6376 - accuracy: 0.0067 - val_loss: 4.1562 - val_accuracy: 0.0167\n",
      "Epoch 156/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.5478 - accuracy: 0.0067 - val_loss: 4.1689 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "300/300 [==============================] - 0s 787us/step - loss: 4.1967 - accuracy: 0.0133 - val_loss: 4.2347 - val_accuracy: 0.0500\n",
      "Epoch 158/200\n",
      "300/300 [==============================] - 0s 850us/step - loss: 4.0954 - accuracy: 0.0167 - val_loss: 3.9673 - val_accuracy: 0.0667\n",
      "Epoch 159/200\n",
      "300/300 [==============================] - 0s 820us/step - loss: 4.2455 - accuracy: 0.0100 - val_loss: 4.5135 - val_accuracy: 0.0667\n",
      "Epoch 160/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.3090 - accuracy: 0.0067 - val_loss: 4.0317 - val_accuracy: 0.0333\n",
      "Epoch 161/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.1602 - accuracy: 0.0033 - val_loss: 4.1453 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.0990 - accuracy: 0.0033 - val_loss: 3.9674 - val_accuracy: 0.0333\n",
      "Epoch 163/200\n",
      "300/300 [==============================] - 0s 763us/step - loss: 4.2605 - accuracy: 0.0233 - val_loss: 4.0143 - val_accuracy: 0.0667\n",
      "Epoch 164/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.2180 - accuracy: 0.0167 - val_loss: 4.2640 - val_accuracy: 0.0667\n",
      "Epoch 165/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 4.3009 - accuracy: 0.0200 - val_loss: 4.0158 - val_accuracy: 0.0500\n",
      "Epoch 166/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.0665 - accuracy: 0.0200 - val_loss: 4.2588 - val_accuracy: 0.0333\n",
      "Epoch 167/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.4559 - accuracy: 0.0100 - val_loss: 4.4862 - val_accuracy: 0.0167\n",
      "Epoch 168/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.2309 - accuracy: 0.0133 - val_loss: 4.0781 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.0814 - accuracy: 0.0233 - val_loss: 4.0551 - val_accuracy: 0.0333\n",
      "Epoch 170/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.2305 - accuracy: 0.0333 - val_loss: 4.2156 - val_accuracy: 0.0833\n",
      "Epoch 171/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.8198 - accuracy: 0.0067 - val_loss: 4.5384 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "300/300 [==============================] - 0s 803us/step - loss: 4.4152 - accuracy: 0.0067 - val_loss: 4.3142 - val_accuracy: 0.0333\n",
      "Epoch 173/200\n",
      "300/300 [==============================] - 0s 767us/step - loss: 4.4176 - accuracy: 0.0200 - val_loss: 4.3473 - val_accuracy: 0.0167\n",
      "Epoch 174/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.0930 - accuracy: 0.0200 - val_loss: 3.9585 - val_accuracy: 0.0500\n",
      "Epoch 175/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.0716 - accuracy: 0.0100 - val_loss: 4.1639 - val_accuracy: 0.0167\n",
      "Epoch 176/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.2698 - accuracy: 0.0100 - val_loss: 4.3500 - val_accuracy: 0.0667\n",
      "Epoch 177/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.1244 - accuracy: 0.0133 - val_loss: 4.5355 - val_accuracy: 0.0500\n",
      "Epoch 178/200\n",
      "300/300 [==============================] - 0s 770us/step - loss: 4.1197 - accuracy: 0.0200 - val_loss: 4.3617 - val_accuracy: 0.1167\n",
      "Epoch 179/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.9934 - accuracy: 0.0100 - val_loss: 4.2721 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "300/300 [==============================] - 0s 773us/step - loss: 4.5234 - accuracy: 0.0033 - val_loss: 4.4294 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.3879 - accuracy: 0.0067 - val_loss: 3.9735 - val_accuracy: 0.0833\n",
      "Epoch 182/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.2867 - accuracy: 0.0133 - val_loss: 4.2385 - val_accuracy: 0.0333\n",
      "Epoch 183/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.3819 - accuracy: 0.0100 - val_loss: 4.6338 - val_accuracy: 0.0167\n",
      "Epoch 184/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.2430 - accuracy: 0.0067 - val_loss: 4.1651 - val_accuracy: 0.0167\n",
      "Epoch 185/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.0570 - accuracy: 0.0233 - val_loss: 4.0791 - val_accuracy: 0.1167\n",
      "Epoch 186/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.0520 - accuracy: 0.0067 - val_loss: 4.1328 - val_accuracy: 0.0167\n",
      "Epoch 187/200\n",
      "300/300 [==============================] - 0s 790us/step - loss: 4.0608 - accuracy: 0.0100 - val_loss: 4.2536 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.8399 - accuracy: 0.0033 - val_loss: 4.7231 - val_accuracy: 0.0500\n",
      "Epoch 189/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.6979 - accuracy: 0.0000e+00 - val_loss: 4.6092 - val_accuracy: 0.0167\n",
      "Epoch 190/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.5195 - accuracy: 0.0133 - val_loss: 4.2768 - val_accuracy: 0.0667\n",
      "Epoch 191/200\n",
      "300/300 [==============================] - 0s 777us/step - loss: 4.3104 - accuracy: 0.0067 - val_loss: 4.3014 - val_accuracy: 0.0167\n",
      "Epoch 192/200\n",
      "300/300 [==============================] - 0s 793us/step - loss: 4.3728 - accuracy: 0.0033 - val_loss: 4.7200 - val_accuracy: 0.0333\n",
      "Epoch 193/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.4554 - accuracy: 0.0100 - val_loss: 4.0768 - val_accuracy: 0.0833\n",
      "Epoch 194/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.3048 - accuracy: 0.0267 - val_loss: 4.0698 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.3748 - accuracy: 0.0133 - val_loss: 4.5009 - val_accuracy: 0.0500\n",
      "Epoch 196/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.2192 - accuracy: 0.0100 - val_loss: 4.1152 - val_accuracy: 0.0167\n",
      "Epoch 197/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.1385 - accuracy: 0.0133 - val_loss: 4.0715 - val_accuracy: 0.0667\n",
      "Epoch 198/200\n",
      "300/300 [==============================] - 0s 780us/step - loss: 4.2562 - accuracy: 0.0100 - val_loss: 4.0835 - val_accuracy: 0.1000\n",
      "Epoch 199/200\n",
      "300/300 [==============================] - 0s 810us/step - loss: 4.3582 - accuracy: 0.0167 - val_loss: 4.1148 - val_accuracy: 0.0167\n",
      "Epoch 200/200\n",
      "300/300 [==============================] - 0s 783us/step - loss: 4.1395 - accuracy: 0.0267 - val_loss: 4.0205 - val_accuracy: 0.0500\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "callback1 = callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#history = model.fit(train_dataset, epochs=1000, validation_data=test_dataset, verbose=1)\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=1, epochs=200, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03333333333333333\n",
      "(-0.268880513652809, 0.0002960292153534677)\n",
      "SpearmanrResult(correlation=-0.3637121067848548, pvalue=6.488429915346749e-07)\n",
      "KendalltauResult(correlation=-0.24024139702105804, pvalue=2.0611479987195184e-06)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.2319278e-02 9.9990082e-01 9.9993181e-01 ... 7.7100992e-03\n",
      "  4.6310127e-03 4.2291880e-03]\n",
      " [3.2171875e-02 9.9990070e-01 9.9993193e-01 ... 7.7168345e-03\n",
      "  4.6416819e-03 4.2349994e-03]\n",
      " [3.1744510e-02 9.9990070e-01 9.9993199e-01 ... 7.7357888e-03\n",
      "  4.6724379e-03 4.2514503e-03]\n",
      " ...\n",
      " [5.7705474e-05 2.3946762e-03 5.7166815e-04 ... 9.9494803e-01\n",
      "  9.9633670e-01 9.9636042e-01]\n",
      " [5.8019792e-05 2.4068952e-03 5.7539344e-04 ... 9.9501836e-01\n",
      "  9.9638271e-01 9.9640441e-01]\n",
      " [5.8315738e-05 2.4186969e-03 5.7917833e-04 ... 9.9508440e-01\n",
      "  9.9642599e-01 9.9644566e-01]]\n"
     ]
    }
   ],
   "source": [
    "nums = list(range(0,300))\n",
    "pred = model.predict(nums)\n",
    "new_pred = []\n",
    "real_values = []\n",
    "i = 0\n",
    "for item in pred:\n",
    "    new_pred.append(transform_predictions(item))\n",
    "    real_values.append(transform_predictions(y_train[i]))\n",
    "    i += 1\n",
    "print(get_accuracy(new_pred, real_values))\n",
    "uncertainty = get_nll_list(y_train, nums, pred)\n",
    "plot_uncertainty_pop(popuarity, uncertainty)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test on bayesian probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, loss, train_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    model.fit(train_dataset, epochs=100, validation_data=test_dataset)\n",
    "    print(\"Model training finished.\")\n",
    "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "    print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test RMSE: {round(rmse, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(1,), dtype=tf.float32\n",
    "        )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_probablistic_bnn_model(train_size):\n",
    "    inputs = create_model_inputs()\n",
    "    features = keras.layers.concatenate(list(inputs.values()))\n",
    "    features = keras.layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with weight uncertainty using the DenseVariational layer.\n",
    "    for units in hidden_units:\n",
    "        features = tfp.layers.DenseVariational(\n",
    "            units=units,\n",
    "            make_prior_fn=prior,\n",
    "            make_posterior_fn=posterior,\n",
    "            kl_weight=1 / train_size,\n",
    "            activation=\"sigmoid\",\n",
    "        )(features)\n",
    "\n",
    "    # Create a probabilistic output (Normal distribution), and use the `Dense` layer\n",
    "    # to produce the parameters of the distribution.\n",
    "    # We set units=2 to learn both the mean and the variance of the Normal distribution.\n",
    "    distribution_params = layers.Dense(units=2)(features)\n",
    "    outputs = tfp.layers.IndependentNormal(1)(distribution_params)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0f2f6c680cf484319d387fabac80ca4ff4fc33965036e02100b3fe02600f1423"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
